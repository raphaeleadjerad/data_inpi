{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ Importation des données TC et TITMC \n",
    "\n",
    "2/ Import et traitement du fichier des prénoms \n",
    "\n",
    "3/ Ajouter le genre des personnes \n",
    "\n",
    "4/ Codification des adresses \n",
    "\n",
    "5/ Ajout et traitement du code commune\n",
    "\n",
    "6/ Retraiter et simplifier les qualités "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction permettant de traiter les données rep et pm et d'ajouter le code commune insee\n",
    "import os\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "def import_inpi():\n",
    "    # Create filesystem object\n",
    "    S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "    fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "    BUCKET = \"radjerad/inpi\"\n",
    "    FILE_KEY_S3 = \"data_rep_pm_2017.csv\"\n",
    "    FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "    with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "        df_rep_pm = pd.read_csv(file_in, sep=\";\", encoding=\"utf-8\", usecols=[\"code greffe\", \"siren\", \"denomination\", \"forme_juridique_x\", \"qualité\",\n",
    "    \"nom_patronymique\", \"nom_usage\", \"prénoms\", \"type\", \"date_naissance\", \"ville_naissance\", \"adresse_ligne1\", \"adresse_ligne2\",\n",
    "    \"adresse_ligne3\", \"code_postal\", \"ville\", \"code_commune\", \"pays\", \"id_représentant\"])\n",
    "    return df_rep_pm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1749/2292492803.py:15: DtypeWarning: Columns (39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_rep_pm = pd.read_csv(file_in, sep=\";\", encoding=\"utf-8\", usecols=[\"code greffe\", \"siren\", \"denomination\", \"forme_juridique_x\", \"qualité\",\n"
     ]
    }
   ],
   "source": [
    "# Lecture de la base inpi\n",
    "\n",
    "df_rep_pm = import_inpi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rep_pm.shape # 9 751 833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diverses corrections \n",
    "\n",
    "def clean_rep_pm_inpi(df_rep_pm):\n",
    "    df_rep_pm = df_rep_pm.rename({\"code greffe\": \"code_greffe\", \n",
    "                                \"forme_juridique_x\": \"forme_juridique\", \n",
    "                                \"prénoms\": \"prenoms\", \"qualité\": \"qualite\", \n",
    "                                \"id_représentant\": \"id_representant\"}, axis=1)\n",
    "    # Traitement des cas où le nom et les prénoms sont manquants\n",
    "    df_rep_pm.loc[df_rep_pm[\"prenoms\"] == \"-\", \"prenoms\"] = \"\"\n",
    "    re1 = \"(INDIVISION SUCCESSORALE DE M\\.\\s|\\sM\\.\\s|^M\\.\\s|MME\\.\\s|MR\\.\\s|MELLE\\.\\s|MONSIEUR\\.?\\s|MADAME\\.?\\s|MLLE\\.\\s|REPRESENTEE\\sPAR\\sMONSIEUR\\.?\\s|REPRESENTEE\\sPAR\\s)\"\n",
    "    # df_rep_pm[\"top_civilite\"] = df_rep_pm[\"nom_patronymique\"].str.contains(re1, regex=True)\n",
    "    df_rep_pm[\"nom_patronymique2\"] = df_rep_pm[\"nom_patronymique\"]\n",
    "    df_rep_pm[\"nom_patronymique2\"] = df_rep_pm[\"nom_patronymique2\"].str.replace(re1,\"\")\n",
    "    # on a modifié un peu le code de l'insee pour enlever les representee par, ici aussi car on va essayer de prendre en compte les particules\n",
    "    particule = \"(DU\\s[A-Za-z]+|DE\\sLA\\s[A-Za-z]+|[A-Za-z]+\\sDU\\s[A-Za-z]+|[A-Za-z]+\\sDE\\sLA\\s[A-Za-z]+|DE\\s[A-Za-z]+|[A-Za-z]+\\sDE\\s[A-Za-z]+)\"\n",
    "    df_rep_pm[\"top_particule\"] = df_rep_pm[\"nom_patronymique\"].str.contains(particule, regex=True)\n",
    "    # Traitement de la qualite\n",
    "    df_rep_pm[\"qualite2\"] = df_rep_pm[\"qualite\"]\n",
    "    df_rep_pm[\"qualite2\"] = df_rep_pm[\"qualite2\"].str.lower()\n",
    "    df_rep_pm[\"qualite2\"] = df_rep_pm[\"qualite2\"].str.strip()\n",
    "    # nettoyage de la dénomination\n",
    "    df_rep_pm[\"denomination2\"] = df_rep_pm[\"denomination\"]\n",
    "    df_rep_pm[\"denomination2\"] = df_rep_pm[\"denomination2\"].str.lower()\n",
    "    # Correction des adresses\n",
    "    df_rep_pm.loc[(df_rep_pm[\"ville\"].isna()) & (df_rep_pm[\"adresse_ligne3\"].isna() == False), \"ville\"] = \\\n",
    "    df_rep_pm.loc[(df_rep_pm[\"ville\"].isna()) & (df_rep_pm[\"adresse_ligne3\"].isna() == False), \"adresse_ligne3\"]\n",
    "    df_rep_pm[\"commune\"] = df_rep_pm[\"ville\"]\n",
    "    df_rep_pm[\"commune\"] = df_rep_pm[\"commune\"].str.lower()\n",
    "    df_rep_pm[\"commune\"] = (df_rep_pm[\"commune\"].str.replace(\"à\", \"a\")\n",
    "                                            .str.replace(\"è\", \"e\")\n",
    "                                            .str.replace(\"é\", \"e\")\n",
    "                                            .str.replace(\"ç\", \"c\")\n",
    "                                            .str.replace(\"ù\", \"u\")\n",
    "                                            .str.replace(\"ô\", \"o\"))\n",
    "    df_rep_pm[\"commune\"] = (df_rep_pm[\"commune\"].str.replace(\"saint\", \"st\"))\n",
    "    df_rep_pm[\"commune\"] = df_rep_pm[\"commune\"].str.replace(\" \", \"\")\n",
    "    return df_rep_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1749/3403239704.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_rep_pm[\"nom_patronymique2\"] = df_rep_pm[\"nom_patronymique2\"].str.replace(re1,\"\")\n",
      "/tmp/ipykernel_1749/3403239704.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_rep_pm[\"top_particule\"] = df_rep_pm[\"nom_patronymique\"].str.contains(particule, regex=True)\n"
     ]
    }
   ],
   "source": [
    "df_rep_pm = clean_rep_pm_inpi(df_rep_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_code_com(df_rep_pm):\n",
    "    S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "    fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "    BUCKET = \"radjerad/diffusion/code_postal\"\n",
    "    FILE_KEY_S3 = \"laposte_hexasmal.csv\"\n",
    "    FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "    with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "        code_postal = pd.read_csv(file_in, sep=\";\")\n",
    "    code_postal.columns = [c.lower() for c in code_postal.columns]\n",
    "    code_postal[\"code_departement\"] = code_postal[\"code_commune_insee\"].str.slice(start=0,stop=2) # code initial de l'insee, a corriger pour les drom\n",
    "    code_postal[\"commune\"] = code_postal[\"nom_commune\"].str.lower()\n",
    "    code_postal[\"commune\"] = (code_postal[\"commune\"].str.replace(\"saint\", \"st\"))\n",
    "    code_postal[\"commune\"] = (code_postal[\"commune\"].str.replace(\"à\", \"a\")\n",
    "                                            .str.replace(\"è\", \"e\")\n",
    "                                            .str.replace(\"é\", \"e\")\n",
    "                                            .str.replace(\"ç\", \"c\")\n",
    "                                            .str.replace(\"ù\", \"u\")\n",
    "                                            .str.replace(\"ô\", \"o\"))\n",
    "    code_postal[\"commune\"] = code_postal[\"commune\"].str.replace(\" \", \"\")\n",
    "    code_postal = code_postal.drop_duplicates(subset = [\"commune\", \"code_departement\"])\n",
    "    code_postal = code_postal.loc[:, [\"code_commune_insee\", \"code_departement\", \"commune\"]]\n",
    "    df_rep_pm[\"code_departement\"] = df_rep_pm[\"code_postal\"].astype(str).str.slice(start=0, stop=2)\n",
    "    df_rep_pm = pd.merge(df_rep_pm, code_postal, on=[\"code_departement\", \"commune\"], how=\"left\")\n",
    "    return df_rep_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_pm = add_code_com(df_rep_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as fc\n",
    "fc.export2minio(\"df_rep_pm_2017_commune.csv\", df_rep_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "BUCKET = \"radjerad/inpi\"\n",
    "FILE_KEY_S3 = \"df_rep_pm_2017_commune.csv\"\n",
    "FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    df_rep_pm = pd.read_csv(file_in, sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on filtre on ne va garder que les lignes avec le nom patronymique, le nom usage, les prénoms, ou la date de naissance\n",
    "df_rep_pm = df_rep_pm.loc[(df_rep_pm[\"nom_patronymique\"].isna() == False) | (df_rep_pm[\"prenoms\"].isna() == False) | \\\n",
    "                            (df_rep_pm[\"date_naissance\"].isna() == False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_pm.shape # 8 671 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_pm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_rep_pm.loc[df_rep_pm[\"code_commune_insee\"].isna() == False, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape # 4 693 722 avec code commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_rep_pm.loc[df_rep_pm[\"code_commune\"].isna() == False, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape  # 7 740 164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_pm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correction pour paris, marseille et lyon\n",
    "df_rep_pm[\"code_commune3\"] = df_rep_pm[\"code_commune\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_pm.loc[(df_rep_pm[\"code_commune3\"].isna()) & (df_rep_pm[\"ville\"] == \"paris\") & (df_rep_pm[\"code_postal\"])]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed5946f2a0d3f5e934efd92075c2a89b2cb5130d0efd6e4509a568bedf48ed26"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('basesspcloud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
